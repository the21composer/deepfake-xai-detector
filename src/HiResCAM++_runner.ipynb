{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:17:06.765656Z","iopub.status.busy":"2024-04-23T19:17:06.765289Z","iopub.status.idle":"2024-04-23T19:18:33.576365Z","shell.execute_reply":"2024-04-23T19:18:33.575379Z","shell.execute_reply.started":"2024-04-23T19:17:06.765593Z"},"trusted":true},"outputs":[],"source":["%pip install grad-cam\n","%pip install torch\n","%pip install skimage\n","%pip install cv2\n","%pip install tqdm\n","%pip install blazeface\n","%pip install torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-23T19:18:33.579102Z","iopub.status.busy":"2024-04-23T19:18:33.578774Z","iopub.status.idle":"2024-04-23T19:18:36.302755Z","shell.execute_reply":"2024-04-23T19:18:36.301683Z","shell.execute_reply.started":"2024-04-23T19:18:33.579044Z"},"trusted":true},"outputs":[],"source":["# Loading the required libraries\n","import os, sys, time\n","import cv2\n","import random\n","import numpy as np\n","import pandas as pd\n","import skimage.transform\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models, transforms\n","from torch.autograd import Variable\n","from torch import topk\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from matplotlib.pyplot import imshow\n","from tqdm.notebook import tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2024-04-23T19:18:36.304493Z","iopub.status.busy":"2024-04-23T19:18:36.304224Z","iopub.status.idle":"2024-04-23T19:18:36.451760Z","shell.execute_reply":"2024-04-23T19:18:36.450947Z","shell.execute_reply.started":"2024-04-23T19:18:36.304441Z"},"trusted":true},"outputs":[],"source":["# Read the test videos \n","test_dir = \"./data\"\n","\n","test_videos = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"])\n","len(test_videos)\n","\n","test_labels = pd.read_csv('./data/labels.csv')\n","test_labels.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:36.453792Z","iopub.status.busy":"2024-04-23T19:18:36.453359Z","iopub.status.idle":"2024-04-23T19:18:38.169020Z","shell.execute_reply":"2024-04-23T19:18:38.168303Z","shell.execute_reply.started":"2024-04-23T19:18:36.453731Z"},"trusted":true},"outputs":[],"source":["test_labels['label'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:38.173174Z","iopub.status.busy":"2024-04-23T19:18:38.172942Z","iopub.status.idle":"2024-04-23T19:18:38.303694Z","shell.execute_reply":"2024-04-23T19:18:38.299980Z","shell.execute_reply.started":"2024-04-23T19:18:38.173136Z"},"trusted":true},"outputs":[],"source":["print(\"PyTorch version:\", torch.__version__)\n","print(\"CUDA version:\", torch.version.cuda)\n","print(\"cuDNN version:\", torch.backends.cudnn.version())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:38.307578Z","iopub.status.busy":"2024-04-23T19:18:38.307087Z","iopub.status.idle":"2024-04-23T19:18:38.443254Z","shell.execute_reply":"2024-04-23T19:18:38.441799Z","shell.execute_reply.started":"2024-04-23T19:18:38.307366Z"},"trusted":true},"outputs":[],"source":["# Check if GPU is available\n","gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","gpu"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:38.445095Z","iopub.status.busy":"2024-04-23T19:18:38.444779Z","iopub.status.idle":"2024-04-23T19:18:38.686635Z","shell.execute_reply":"2024-04-23T19:18:38.685678Z","shell.execute_reply.started":"2024-04-23T19:18:38.445051Z"},"trusted":true},"outputs":[],"source":["# Attach the required libraries to the system path\n","# This have a few helper functions & path to the pre-trained model\n","\n","import sys\n","sys.path.insert(0, \"/kaggle/input/blazeface-pytorch\")\n","sys.path.insert(0, \"/kaggle/input/deepfakes-inference-demo\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:38.688786Z","iopub.status.busy":"2024-04-23T19:18:38.688457Z","iopub.status.idle":"2024-04-23T19:18:41.965268Z","shell.execute_reply":"2024-04-23T19:18:41.964306Z","shell.execute_reply.started":"2024-04-23T19:18:38.688737Z"},"trusted":true},"outputs":[],"source":["# Initalize blazeface \n","\n","from blazeface import BlazeFace\n","facedet = BlazeFace().to(gpu)\n","facedet.load_weights(\"/kaggle/input/blazeface-pytorch/blazeface.pth\")\n","facedet.load_anchors(\"/kaggle/input/blazeface-pytorch/anchors.npy\")\n","_ = facedet.train(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:41.966847Z","iopub.status.busy":"2024-04-23T19:18:41.966554Z","iopub.status.idle":"2024-04-23T19:18:41.992404Z","shell.execute_reply":"2024-04-23T19:18:41.991649Z","shell.execute_reply.started":"2024-04-23T19:18:41.966796Z"},"trusted":true},"outputs":[],"source":["from read_video_1 import VideoReader\n","from face_extract_1 import FaceExtractor\n","\n","frames_per_video = 16\n","\n","video_reader = VideoReader()\n","video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n","face_extractor = FaceExtractor(video_read_fn, facedet)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:41.994062Z","iopub.status.busy":"2024-04-23T19:18:41.993762Z","iopub.status.idle":"2024-04-23T19:18:46.030102Z","shell.execute_reply":"2024-04-23T19:18:46.029308Z","shell.execute_reply.started":"2024-04-23T19:18:41.994009Z"},"trusted":true},"outputs":[],"source":["input_size = 224 # Define the input size of the image\n","\n","# Define the normalizing functions with ImageNet parameters \n","from torchvision.transforms import Normalize\n","\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","normalize_transform = Normalize(mean, std)\n","\n","# Define some helper functions for re-sizing image & making them into perfect squares\n","def isotropically_resize_image(img, size, resample=cv2.INTER_AREA):\n","    h, w = img.shape[:2]\n","    if w > h:\n","        h = h * size // w\n","        w = size\n","    else:\n","        w = w * size // h\n","        h = size\n","\n","    resized = cv2.resize(img, (w, h), interpolation=resample)\n","    return resized\n","\n","\n","def make_square_image(img):\n","    h, w = img.shape[:2]\n","    size = max(h, w)\n","    t = 0\n","    b = size - h\n","    l = 0\n","    r = size - w\n","    return cv2.copyMakeBorder(img, t, b, l, r, cv2.BORDER_CONSTANT, value=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:46.031921Z","iopub.status.busy":"2024-04-23T19:18:46.031605Z","iopub.status.idle":"2024-04-23T19:18:46.043387Z","shell.execute_reply":"2024-04-23T19:18:46.042582Z","shell.execute_reply.started":"2024-04-23T19:18:46.031864Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torchvision.models as models\n","\n","class MyResNeXt(models.resnet.ResNet):\n","    def __init__(self, training=True):\n","        super(MyResNeXt, self).__init__(block=models.resnet.Bottleneck,\n","                                        layers=[3, 4, 6, 3], \n","                                        groups=32, \n","                                        width_per_group=4)\n","        \n","        self.fc = nn.Linear(2048, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:46.044863Z","iopub.status.busy":"2024-04-23T19:18:46.044606Z","iopub.status.idle":"2024-04-23T19:18:47.516547Z","shell.execute_reply":"2024-04-23T19:18:47.515895Z","shell.execute_reply.started":"2024-04-23T19:18:46.044817Z"},"trusted":true},"outputs":[],"source":["#Load the checkpoint & update the model for prediction\n","checkpoint = torch.load(\"./resnext.pth\", map_location=gpu)\n","\n","model = MyResNeXt().to(gpu)\n","model.load_state_dict(checkpoint)\n","_ = model.eval()\n","\n","del checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:47.518279Z","iopub.status.busy":"2024-04-23T19:18:47.517972Z","iopub.status.idle":"2024-04-23T19:18:47.524214Z","shell.execute_reply":"2024-04-23T19:18:47.523488Z","shell.execute_reply.started":"2024-04-23T19:18:47.518221Z"},"trusted":true},"outputs":[],"source":["y = 'REAL'\n","while y == 'REAL':\n","    sample_video= random.choice(test_videos) # Select a random test video \n","    #coadfnerlk.mp4\n","    #zgbhzkditd.mp4\n","    #bwdmzwhdnw.mp4\n","    #sample_video = 'zgbhzkditd.mp4'\n","    video_path = os.path.join(test_dir, sample_video)\n","    #y = test_labels[test_labels['processedVideo'] == sample_video]['label'].values[0]\n","    y = 'FAKE'\n","print(\"Selected Video: \", sample_video)\n","#print(\"True Value: \",y)\n","#zcxcmneefk.mp4\n","#lmdyicksrv.mp4\n","#jhczqfefgw.mp4\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:47.525977Z","iopub.status.busy":"2024-04-23T19:18:47.525687Z","iopub.status.idle":"2024-04-23T19:18:49.244284Z","shell.execute_reply":"2024-04-23T19:18:49.243455Z","shell.execute_reply.started":"2024-04-23T19:18:47.525925Z"},"trusted":true},"outputs":[],"source":["batch_size = 16 # Extract faces from 16 frames in the video\n","faces = face_extractor.process_video(video_path)\n","print(\"No. of frames extracted: \", len(faces))\n","print(\"Keys in the extracted info: \", faces[0].keys())\n","try:\n","    print(\"Shape of extracted face_crop: \", faces[0]['faces'][0].shape) # multiple faces can be captured. In this set only a single face is detected\n","    print(\"Scores of the face crop: \", faces[0]['scores'][0])\n","except:\n","    print(\"=====================================\")\n","    print(\"No faces detected! Please run again.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:49.245664Z","iopub.status.busy":"2024-04-23T19:18:49.245359Z","iopub.status.idle":"2024-04-23T19:18:49.249002Z","shell.execute_reply":"2024-04-23T19:18:49.248334Z","shell.execute_reply.started":"2024-04-23T19:18:49.245545Z"},"trusted":true},"outputs":[],"source":["# Only look at one face per frame. This removes multiple faces from each frame, keeping only the best face\n","face_extractor.keep_only_best_face(faces)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:49.251103Z","iopub.status.busy":"2024-04-23T19:18:49.250846Z","iopub.status.idle":"2024-04-23T19:18:49.259931Z","shell.execute_reply":"2024-04-23T19:18:49.259186Z","shell.execute_reply.started":"2024-04-23T19:18:49.251045Z"},"trusted":true},"outputs":[],"source":["print(len(faces))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:49.261253Z","iopub.status.busy":"2024-04-23T19:18:49.260994Z","iopub.status.idle":"2024-04-23T19:18:49.273807Z","shell.execute_reply":"2024-04-23T19:18:49.273056Z","shell.execute_reply.started":"2024-04-23T19:18:49.261201Z"},"trusted":true},"outputs":[],"source":["sample_face = faces[1]['faces'][0]\n","resized_face = isotropically_resize_image(sample_face, input_size)\n","resized_face = make_square_image(resized_face)\n","resized_face.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:49.275329Z","iopub.status.busy":"2024-04-23T19:18:49.275026Z","iopub.status.idle":"2024-04-23T19:18:49.282713Z","shell.execute_reply":"2024-04-23T19:18:49.281777Z","shell.execute_reply.started":"2024-04-23T19:18:49.275276Z"},"trusted":true},"outputs":[],"source":["x = torch.tensor(resized_face, device=gpu).float()\n","print(x.shape)\n","# Preprocess the images.\n","x = x.permute(( 2, 0, 1))\n","x = normalize_transform(x / 255.)\n","x = x.unsqueeze(0)\n","print(x.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:49.284317Z","iopub.status.busy":"2024-04-23T19:18:49.284014Z","iopub.status.idle":"2024-04-23T19:18:49.292257Z","shell.execute_reply":"2024-04-23T19:18:49.291618Z","shell.execute_reply.started":"2024-04-23T19:18:49.284266Z"},"trusted":true},"outputs":[],"source":["prediction_var = Variable(x.cuda(), requires_grad=True) # Squeeze the  variable to add an additional dimension & then\n","prediction_var.shape                                    # wrap it in a Variable which stores the grad_training weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:49.293468Z","iopub.status.busy":"2024-04-23T19:18:49.293239Z","iopub.status.idle":"2024-04-23T19:18:49.322816Z","shell.execute_reply":"2024-04-23T19:18:49.322151Z","shell.execute_reply.started":"2024-04-23T19:18:49.293417Z"},"trusted":true},"outputs":[],"source":["y_pred = model(prediction_var)\n","y_pred = torch.sigmoid(y_pred.squeeze())\n","\n","print(\"Prediction: \", y_pred)\n","pred_probabilities = F.softmax(y_pred).data.squeeze() # Pass the predictions through a softmax layer to convert into probabilities for each class\n","print(\"Predicted Class: \", pred_probabilities)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:49.324333Z","iopub.status.busy":"2024-04-23T19:18:49.324043Z","iopub.status.idle":"2024-04-23T19:18:49.689107Z","shell.execute_reply":"2024-04-23T19:18:49.688227Z","shell.execute_reply.started":"2024-04-23T19:18:49.324281Z"},"trusted":true},"outputs":[],"source":["from pytorch_grad_cam import HiResCAM, GradCAM\n","from pytorch_grad_cam.utils.model_targets import BinaryClassifierOutputTarget\n","from pytorch_grad_cam.utils.image import show_cam_on_image\n","\n","def repeat_matrix(matrix, N):\n","    m, n = matrix.shape\n","    new_shape = (m * N, n * N)\n","    repeated_matrix = np.empty(new_shape)\n","\n","    for i in range(m * N):\n","        for j in range(n * N):\n","            repeated_matrix[i, j] = 1 / (1 + np.exp(10 * (-(matrix[i // N, j // N] - 0.5))))\n","\n","    return repeated_matrix\n","\n","def initCAM(model, target_layers):\n","    cam_last = HiResCAM(model=model, target_layers=target_layers[0], use_cuda=True)\n","    cam_prelast = HiResCAM(model=model, target_layers=target_layers[1], use_cuda=True)\n","    return [cam_last, cam_prelast]\n","\n","def getHiResCAM(data, cams, targets):\n","    grayscale_cam_last = cams[0](input_tensor=data, targets=targets)\n","    grayscale_cam_last = grayscale_cam_last[0, :]\n","    grayscale_cam_prelast = cams[1](input_tensor=data, targets=targets)\n","    grayscale_cam_prelast = grayscale_cam_prelast[0, :]\n","    output = repeat_matrix(grayscale_cam_last, 1) * grayscale_cam_prelast\n","    return grayscale_cam_last, grayscale_cam_prelast, output\n","\n","cams = initCAM(model, [[model.layer4[-1]], [model.layer3[-1]]])\n","\n","#imshow(visualization)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T19:18:49.690764Z","iopub.status.busy":"2024-04-23T19:18:49.690456Z","iopub.status.idle":"2024-04-23T19:19:17.507437Z","shell.execute_reply":"2024-04-23T19:19:17.506181Z","shell.execute_reply.started":"2024-04-23T19:18:49.690714Z"},"trusted":true},"outputs":[],"source":["target = [BinaryClassifierOutputTarget(1)]\n","def explainDeepFake(samples):\n","    output = []\n","    for sample in samples:\n","        if (len(sample['faces'])):\n","            sample_face = sample['faces'][0]\n","            resized_face = isotropically_resize_image(sample_face, input_size)\n","            resized_face = make_square_image(resized_face)\n","            resized_face.shape\n","            x = torch.tensor(resized_face, device=gpu).float()\n","            x = x.permute(( 2, 0, 1))\n","            x = normalize_transform(x / 255.)\n","            x = x.unsqueeze(0)\n","            prediction_var = Variable(x.cuda(), requires_grad=True)\n","            grayscale_cam_last, grayscale_cam_prelast, hirescamplus_cam = getHiResCAM(prediction_var, cams, target)\n","            resized_face_norm = resized_face / 255\n","            output.append([grayscale_cam_last, grayscale_cam_prelast, hirescamplus_cam, resized_face_norm])\n","    return output\n","\n","output = explainDeepFake(faces)\n","fig, ax = plt.subplots(16,4, figsize=(30,160))\n","i = 0\n","for explain in output:\n","    visualization_last = show_cam_on_image(explain[3], explain[0], use_rgb=True)\n","    ax[i, 0].imshow(visualization_last)\n","    visualization_last = show_cam_on_image(explain[3], explain[1], use_rgb=True)\n","    ax[i, 1].imshow(visualization_last)\n","    visualization_last = show_cam_on_image(explain[3], explain[2], use_rgb=True)\n","    ax[i, 2].imshow(visualization_last)\n","    ax[i, 3].imshow(explain[3])\n","    i += 1\n","        "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":858837,"sourceId":16880,"sourceType":"competition"},{"datasetId":458848,"sourceId":888125,"sourceType":"datasetVersion"},{"datasetId":484608,"sourceId":904207,"sourceType":"datasetVersion"},{"datasetId":492598,"sourceId":1008856,"sourceType":"datasetVersion"}],"dockerImageVersionId":29845,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
